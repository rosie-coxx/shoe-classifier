{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipyfilechooser\n",
    "!pip install scikit-image\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import widgets\n",
    "from ipyfilechooser import FileChooser\n",
    " \n",
    "# Helper function to calculate similarity\n",
    "def calculate_similarity(image1_path, image2_path):\n",
    "    image1 = Image.open(image1_path).convert('L')\n",
    "    image2 = Image.open(image2_path).convert('L')\n",
    "\n",
    "    image1 = image1.resize((256, 256))\n",
    "    image2 = image2.resize((256, 256))\n",
    "\n",
    "    image1_np = np.array(image1)\n",
    "    image2_np = np.array(image2)\n",
    "\n",
    "    similarity_index, _ = ssim(image1_np, image2_np, full=True)\n",
    "    return similarity_index\n",
    "\n",
    "# Widget to upload an image\n",
    "file_chooser = FileChooser('/lakehouse/default/Files/upload_files') \n",
    "display(file_chooser)\n",
    "\n",
    "def find_sole_images(root_dir):\n",
    "    sole_images = []\n",
    "    valid_extensions = {'.png', '.jpg', '.jpeg', '.jfif', '.bmp', '.gif', '.tiff'}\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            file_name, file_extension = os.path.splitext(file)\n",
    "            if file_name.lower() == 'sole' and file_extension.lower() in valid_extensions:\n",
    "                sole_images.append(os.path.join(subdir, file))\n",
    "    return sole_images\n",
    "\n",
    "def compare_uploaded_image(file_chooser, root_dir):\n",
    "\n",
    "    uploaded_image_path = file_chooser.selected\n",
    "\n",
    "    if uploaded_image_path:\n",
    "        print(f\"Selected file: {uploaded_image_path}\")\n",
    "        \n",
    "        \n",
    "        sole_images = find_sole_images(root_dir)\n",
    "\n",
    "        similarities = []\n",
    "        \n",
    "        for sole_image in sole_images:\n",
    "            similarity = calculate_similarity(uploaded_image_path, sole_image)\n",
    "            # Add the similarity score and the sole image path to the results  \n",
    "            similarities.append((os.path.relpath(sole_image, root_dir), similarity))\n",
    "        \n",
    "        # Sort the results by similarity in descending order - the most likely\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Create a DataFrame to store the results\n",
    "        df = pd.DataFrame(similarities, columns=['File Path', 'Similarity'])\n",
    "        \n",
    "        # Save the results to a CSV file\n",
    "        csv_path = '/lakehouse/default/Files/data/similarity_results.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Display the results as a table\n",
    "        display(HTML(df.to_html(index=False)))\n",
    "        \n",
    "        print(f'Results saved to {csv_path}')\n",
    "    else:\n",
    "        print(\"Please upload an image first.\")\n",
    "\n",
    "root_dir = '/lakehouse/default/Files/Shoe'  # Need to check this is the right file path \n",
    "\n",
    "compare_button = widgets.Button(description=\"Compare Images\")\n",
    "display(compare_button)\n",
    "\n",
    "def on_compare_button_clicked(b):\n",
    "    compare_uploaded_image(file_chooser, root_dir)\n",
    "\n",
    "compare_button.on_click(on_compare_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow ipyfilechooser scikit-image opencv-python-headless\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage import feature\n",
    "import cv2  # Import OpenCV\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Helper function to calculate similarity using edge detection and CNN feature extraction\n",
    "def calculate_similarity(image1_path, image2_path):\n",
    "    def preprocess_and_extract_features(img_path):\n",
    "        # Load and preprocess image\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        \n",
    "        # Convert to grayscale and apply edge detection\n",
    "        gray_img = cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)\n",
    "        edges = feature.canny(gray_img).astype(float)\n",
    "\n",
    "        # Convert back to 3 channels\n",
    "        edges = np.stack([edges, edges, edges], axis=-1)\n",
    "\n",
    "        # Preprocess for ResNet\n",
    "        edges = np.expand_dims(edges, axis=0)\n",
    "        edges = preprocess_input(edges)\n",
    "\n",
    "        # Extract features using CNN\n",
    "        features = model.predict(edges)\n",
    "        return features\n",
    "\n",
    "    features1 = preprocess_and_extract_features(image1_path)\n",
    "    features2 = preprocess_and_extract_features(image2_path)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Widget to upload an image\n",
    "file_chooser = FileChooser('/lakehouse/default/Files/upload_files')\n",
    "display(file_chooser)\n",
    "\n",
    "def find_sole_images(root_dir):\n",
    "    sole_images = []\n",
    "    valid_extensions = {'.png', '.jpg', '.jpeg', '.jfif', '.bmp', '.gif', '.tiff'}\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            file_name, file_extension = os.path.splitext(file)\n",
    "            if file_name.lower() == 'sole' and file_extension.lower() in valid_extensions:\n",
    "                sole_images.append(os.path.join(subdir, file))\n",
    "    return sole_images\n",
    "\n",
    "def compare_uploaded_image(file_chooser, root_dir):\n",
    "    uploaded_image_path = file_chooser.selected\n",
    "\n",
    "    if uploaded_image_path:\n",
    "        print(f\"Selected file: {uploaded_image_path}\")\n",
    "        \n",
    "        sole_images = find_sole_images(root_dir)\n",
    "        similarities = []\n",
    "        \n",
    "        for sole_image in sole_images:\n",
    "            similarity = calculate_similarity(uploaded_image_path, sole_image)\n",
    "            # Add the similarity score and the sole image path to the results  \n",
    "            similarities.append((os.path.relpath(sole_image, root_dir), similarity))\n",
    "        \n",
    "        # Sort the results by similarity in descending order - the most likely\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Create a DataFrame to store the results\n",
    "        df = pd.DataFrame(similarities, columns=['File Path', 'Similarity'])\n",
    "        \n",
    "        # Save the results to a CSV file\n",
    "        csv_path = '/lakehouse/default/Files/data/similarity_results.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Display the results as a table\n",
    "        display(HTML(df.to_html(index=False)))\n",
    "        \n",
    "        print(f'Results saved to {csv_path}')\n",
    "    else:\n",
    "        print(\"Please upload an image first.\")\n",
    "\n",
    "root_dir = '/lakehouse/default/Files/Shoe'  # Ensure this is the right file path \n",
    "\n",
    "compare_button = widgets.Button(description=\"Compare Images\")\n",
    "display(compare_button)\n",
    "\n",
    "def on_compare_button_clicked(b):\n",
    "    compare_uploaded_image(file_chooser, root_dir)\n",
    "\n",
    "compare_button.on_click(on_compare_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage import feature\n",
    "import cv2\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Helper function to calculate similarity using edge detection and CNN feature extraction\n",
    "def calculate_similarity(image1_path, image2_path):\n",
    "    def preprocess_and_extract_features(img_path):\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)\n",
    "        edges = feature.canny(gray_img).astype(float)\n",
    "\n",
    "        edges = np.stack([edges, edges, edges], axis=-1)\n",
    "        edges = np.expand_dims(edges, axis=0)\n",
    "        edges = preprocess_input(edges)\n",
    "\n",
    "        features = model.predict(edges)\n",
    "        return features\n",
    "\n",
    "    features1 = preprocess_and_extract_features(image1_path)\n",
    "    features2 = preprocess_and_extract_features(image2_path)\n",
    "\n",
    "    similarity = cosine_similarity(features1, features2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "# file chooser to upload an image\n",
    "file_chooser = FileChooser('/lakehouse/default/Files/upload_files')\n",
    "display(file_chooser)\n",
    "\n",
    "def find_sole_images(root_dir):\n",
    "    sole_images = []\n",
    "    valid_extensions = {'.png', '.jpg', '.jpeg', '.jfif', '.bmp', '.gif', '.tiff'}\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            file_name, file_extension = os.path.splitext(file)\n",
    "            if file_name.lower() == 'sole' and file_extension.lower() in valid_extensions:\n",
    "                sole_images.append(os.path.join(subdir, file))\n",
    "    return sole_images\n",
    "\n",
    "def compare_uploaded_image(file_chooser, root_dir):\n",
    "    uploaded_image_path = file_chooser.selected\n",
    "\n",
    "    if uploaded_image_path:\n",
    "        print(f\"Selected file: {uploaded_image_path}\")\n",
    "        \n",
    "        sole_images = find_sole_images(root_dir)\n",
    "        similarities = []\n",
    "        \n",
    "        for sole_image in sole_images:\n",
    "            similarity = calculate_similarity(uploaded_image_path, sole_image)\n",
    "            similarities.append((os.path.relpath(sole_image, root_dir), similarity))\n",
    "        \n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        df = pd.DataFrame(similarities, columns=['File Path', 'Similarity'])\n",
    "        \n",
    "        csv_path = '/lakehouse/default/Files/data/similarity_results.csv'\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        display(HTML(df.to_html(index=False)))\n",
    "        \n",
    "        print(f'Results saved to {csv_path}')\n",
    "        \n",
    "        # Create widgets for feedback to help improve the model \n",
    "        feedback_button = widgets.Button(description=\"Submit Correction\")\n",
    "        correction_text = widgets.Text(description=\"Correct File Path:\")\n",
    "        display(feedback_button, correction_text)\n",
    "\n",
    "        def on_feedback_button_clicked(b):\n",
    "            correct_path = correction_text.value\n",
    "            if correct_path:\n",
    "                with open('/lakehouse/default/Files/data/corrections.csv', 'a') as f: ## we might want to change the location and create a folder for it \n",
    "                    f.write(f\"{uploaded_image_path},{correct_path}\\n\")\n",
    "                print(f\"Correction submitted: {correct_path}\")\n",
    "            else:\n",
    "                print(\"Please enter a correction.\")\n",
    "\n",
    "        feedback_button.on_click(on_feedback_button_clicked)\n",
    "    else:\n",
    "        print(\"Please upload an image first.\")\n",
    "\n",
    "root_dir = '/lakehouse/default/Files/Shoe'\n",
    "\n",
    "compare_button = widgets.Button(description=\"Compare Images\")\n",
    "display(compare_button)\n",
    "\n",
    "def on_compare_button_clicked(b):\n",
    "    compare_uploaded_image(file_chooser, root_dir)\n",
    "\n",
    "compare_button.on_click(on_compare_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load corrections for learning\n",
    "corrections = pd.read_csv('/lakehouse/default/Files/data/corrections.csv', header=None, names=['incorrect_path', 'correct_path'])\n",
    "\n",
    "# Prepare training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for _, row in corrections.iterrows():\n",
    "    train_data.append(row['correct_path'])\n",
    "    train_labels.append(row['correct_path'].split('/')[-2])  # Assuming label is the second last folder name\n",
    "\n",
    "# Create an ImageDataGenerator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'filename': train_data, 'class': train_labels}),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'filename': train_data, 'class': train_labels}),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Fine-tune the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('/lakehouse/default/Files/data/fine_tuned_model.h5') ##might need to change this file path too \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
